import os
import re
import subprocess
import requests
from config import OPENAI_API_KEY

# –®–ª—è—Ö –¥–æ –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É
AUDIO_FILE = "audio/2025-03-08-audio.mp4"
TRIMMED_AUDIO_FILE = "audio/trimmed_lecture.mp4"

# –õ—ñ–º—ñ—Ç –¥–ª—è OpenAI API (25MB)
FILE_SIZE_LIMIT_MB = 25

def get_file_size(file_path):
    return os.path.getsize(file_path) / (1024 * 1024)

def detect_voice_start(file_path):
    """
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ffmpeg –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–º–µ–Ω—Ç—É, –∫–æ–ª–∏ –∑–∞–∫—ñ–Ω—á—É—î—Ç—å—Å—è —Ç–∏—à–∞.
    –§—É–Ω–∫—Ü—ñ—è —à—É–∫–∞—î —Ä—è–¥–æ–∫ —Ç–∏–ø—É "silence_end: <—á–∞—Å>" –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤–∏—Ä–∞–∑—É.
    """
    command = [
        "ffmpeg", "-i", file_path,
        "-af", "silencedetect=noise=-40dB:d=0.5",
        "-f", "null", "-"
    ]
    result = subprocess.run(command, stderr=subprocess.PIPE, text=True)
    # –†–æ–∑–∫–æ–º–µ–Ω—Ç—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ä—è–¥–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É –≤–∏–≤–æ–¥—É ffmpeg, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—ñ–¥–ª–∞–≥–æ–¥–∂–µ–Ω–Ω—è:
    # print(result.stderr)
    match = re.search(r"silence_end:\s*([\d\.]+)", result.stderr)
    if match:
        return match.group(1)  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —á–∞—Å –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è —Ç–∏—à—ñ
    return None  # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ None

def trim_silence(file_path, output_path):
    start_time = detect_voice_start(file_path)
    if start_time:
        print(f"üîπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–±—Ä—ñ–∑–∞—é —Ç–∏—à—É –¥–æ {start_time} —Å–µ–∫—É–Ω–¥–∏...")
        # –í–∏–∫–æ–Ω—É—î–º–æ –æ–±—Ä—ñ–∑–∞–Ω–Ω—è –∑ –ø–µ—Ä–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è–º –∞—É–¥—ñ–æ –¥–ª—è —Ç–æ—á–Ω—ñ—à–æ–≥–æ –æ–±—Ä—ñ–∑–∞–Ω–Ω—è
        command = [
            "ffmpeg", "-i", file_path,
            "-ss", start_time,
            "-c:a", "aac", "-b:a", "128k",  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ
            output_path
        ]
        subprocess.run(command, check=True)
        return output_path
    else:
        print("üîπ –¢–∏—à–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ –∞–±–æ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫–∞. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª.")
        return file_path

def split_audio(file_path, output_folder, segment_length=300):
    """
    –†–æ–∑–±–∏–≤–∞—î –∞—É–¥—ñ–æ—Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ –ø–æ 5 —Ö–≤–∏–ª–∏–Ω (300 —Å–µ–∫—É–Ω–¥)
    —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î —ó—Ö —É —Ñ–æ—Ä–º–∞—Ç—ñ MP3 –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º libmp3lame.
    """
    os.makedirs(output_folder, exist_ok=True)
    output_pattern = os.path.join(output_folder, "part_%03d.mp3")
    command = [
        "ffmpeg", "-i", file_path,
        "-f", "segment",
        "-segment_time", str(segment_length),
        "-c:a", "libmp3lame", "-b:a", "128k",
        output_pattern
    ]
    subprocess.run(command, check=True)
    return sorted([os.path.join(output_folder, f) for f in os.listdir(output_folder) if f.endswith(".mp3")])


def transcribe_audio(file_path):
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    with open(file_path, "rb") as file:
        files = {"file": file}
        data = {
            "model": "whisper-1",
            "language": "uk",
            "temperature": 0,
            "prompt": "",
            "response_format": "json"
        }
        print(f"–í—ñ–¥–ø—Ä–∞–≤–ª—è—é {file_path} –¥–æ OpenAI Whisper API...")
        response = requests.post("https://api.openai.com/v1/audio/transcriptions",
                                 headers=headers, files=files, data=data)
        response.raise_for_status()
        return response.json()["text"]

# –û–±—Ä—ñ–∑–∞—î–º–æ —Ç–∏—à—É –ø–µ—Ä–µ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—î—é –∞–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª
AUDIO_FILE = trim_silence(AUDIO_FILE, TRIMMED_AUDIO_FILE)

# –í–∏–∫–æ–Ω–∞–Ω–Ω—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó
if get_file_size(AUDIO_FILE) > FILE_SIZE_LIMIT_MB:
    print("üîπ –§–∞–π–ª –∑–∞–≤–µ–ª–∏–∫–∏–π, —Ä–æ–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏...")
    parts = split_audio(AUDIO_FILE, "audio_parts")
    transcriptions = []
    for part in parts:
        transcription = transcribe_audio(part)
        transcriptions.append(transcription)
    full_transcription = "\n".join(transcriptions)
else:
    print("üîπ –§–∞–π–ª –º–µ–Ω—à–∏–π –∑–∞ 25MB, –≤—ñ–¥–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ä–æ–∑–±–∏—Ç—Ç—è...")
    full_transcription = transcribe_audio(AUDIO_FILE)

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó —É —Ñ–∞–π–ª
OUTPUT_FILE = "output/lecture.txt"
os.makedirs("output", exist_ok=True)
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    f.write(full_transcription)

print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {OUTPUT_FILE}")
